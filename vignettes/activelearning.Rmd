---
title: "Active Learning"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{activelearning}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(activelearning)
library(sits)
library(caret)
library(dplyr)
library(ensurer)
library(magrittr)
library(terra)

n_samples <- 20
n_iterations <- 30
n_multicores <- 2

```



```{r util, include=FALSE}

#' Compute accuracy by comparing a reference to a prediction raster.
#'
#' @param ref_rast   A terra's raster of reference.
#' @param pred_rast  A terra's raster with predictions.
#' @param ref_labels A named character. The names of the labels in ref_rast.
#' @return           A named numeric character. The overall, producer and user
#'                   accuracy.
compute_accuracy <- function(ref_rast, pred_rast, ref_labels) {

    reference_vec  <- dplyr::recode(ref_rast[], !!!ref_labels)
    prediction_vec <- dplyr::recode(pred_rast[], !!!ref_labels)

    conf_mat <- caret::confusionMatrix(data = factor(prediction_vec,
                                                     levels = ref_labels),
                                       reference = factor(reference_vec,
                                                          levels = ref_labels))
    cf_mat <- as.matrix(conf_mat[["table"]])
    overall_accuracy  <- conf_mat$overall["Accuracy"]
    producer_accuracy <- diag(cf_mat) / colSums(cf_mat)
    names(producer_accuracy) <- paste0(names(producer_accuracy), "_pa")
    user_accuracy     <- diag(cf_mat) / rowSums(cf_mat)
    names(user_accuracy) <- paste0(names(user_accuracy), "_ua")

    pua <- c(producer_accuracy, user_accuracy)
    pua <- pua[match(sort(names(pua)), names(pua))]

    return(c(overall_accuracy, pua))
}

#' Count the number of NAs in a tibble.
#'
#' @param x A tibble.
#' @return  An integer.
#'                   accuracy.
count_ts_na <- function(x){
  sum(is.na(x))
}

```



## Ground truth

```{r base_classification, echo=FALSE, fig.width=9, fig.height=5}

#---- Do a full classification and use it as ground truth ----

classification_interval <- c(as.Date("2013-09-14"),
                             as.Date("2014-08-29"))

samples_tb <- sits::samples_modis_4bands %>%
    sits::sits_select(bands = c("NDVI", "EVI")) %>%
    # Test for NA in the time series.
    dplyr::mutate(n_na = purrr::map_int(time_series, count_ts_na)) %>%
    ensurer::ensure_that(all(.$n_na == 0),
                         err_desc = "NAs found!") %>%
    dplyr::select(-n_na)

data_cube <- sits::sits_cube(
    source = "LOCAL",
    name = "sinop-2014",
    satellite = "TERRA",
    sensor = "MODIS",
    data_dir = system.file("extdata/raster/mod13q1", package = "sits"),
    delim = "_",
    parse_info = c("X1", "X2", "tile", "band", "date"),
    start_date = dplyr::first(classification_interval),
    end_date   = dplyr::last(classification_interval)
)

sits_method <- sits::sits_xgboost(verbose = FALSE)
#sits_method <- sits::sits_rfor(num_trees = 1000)
sits_model  <- sits::sits_train(samples_tb, ml_method = sits_method)
probs_cube  <- sits::sits_classify(data_cube,
                                   ml_model = sits_model,
                                   output_dir = tempdir(),
                                   memsize = 4,
                                   multicores = 1)

label_cube <- sits::sits_label_classification(probs_cube,
                                              output_dir = tempdir())

ref_labels <- environment((sits_model))[["labels"]]
names(ref_labels) <- as.character(1:length(ref_labels))

# Get a raster with the ground truth.
ref_rast <- rast(label_cube[["file_info"]][[1]][["path"]])

plot(label_cube, main = "Ground truth")

```



## Random sampling

```{r random_sampling, echo=FALSE, fig.width=9, fig.height=5}

# First set of samples for starting Active Learning.
al_samples_tb <- samples_tb %>%
    dplyr::group_by(label) %>%
    dplyr::sample_n(5) %>%
    dplyr::ungroup() %>%
    magrittr::set_class(class(sits::samples_modis_4bands))

results_lt <- list()
for (i in 1:n_iterations) {
    out_dir <- file.path(tempdir(), paste0("iter_rs_", i))
    dir.create(out_dir)

    # NOTE: Since the cube's extent is small, we can run a classification of the
    #       whole area to estimate its accuracy. A more realistic scenario would
    #       use sample points.
    al_sits_model  <- sits::sits_train(al_samples_tb,
                                       ml_method = sits_method)
    al_probs_cube <- sits::sits_classify(data_cube,
                                         ml_model = al_sits_model,
                                         output_dir = out_dir,
                                         memsize = 4,
                                         multicores = 1)
    al_label_cube <- sits::sits_label_classification(al_probs_cube,
                                                     output_dir = out_dir)
    
    # Compute classification's accuracy.
    accuracy_vec <- compute_accuracy(
        ref_rast = ref_rast,
        pred_rast = rast(al_label_cube$file_info[[1]][["path"]]),
        ref_labels = ref_labels
    )
    results_lt[[i]] <- c(n_samples = nrow(al_samples_tb), accuracy_vec)

    if (i == n_iterations)
        next()

    # Get new samples using active learning.
    suppressMessages(
      oracle_samples <- al_samples_tb %>%
        sits_al_random_sampling(sits_method = sits_method,
                                data_cube = data_cube,
                                n_samples = 1000,
                                multicores = n_multicores)
    )
    oracle_samples <- oracle_samples %>%
        dplyr::arrange(dplyr::desc(entropy)) %>%
        dplyr::slice(1:(n_samples)) %>%
        dplyr::select(longitude:time_series)

    # NOTE: Here we should go to the oracle. Instead, we're getting labels from
    #       the reference raster.
    oracle_sf <-  sf::st_as_sf(oracle_samples,
                               coords = c("longitude", "latitude"),
                               crs = 4326) %>%
        sf::st_transform(crs = crs(ref_rast))
    oracle_labels <- terra::extract(ref_rast, terra::vect(oracle_sf)) %>%
        pull(lyr1) %>%
        recode(!!!ref_labels)

    # Update the labels using data from the oracle.
    oracle_samples[["label"]] <- oracle_labels

    # Merge the new samples to the sample data set.
    al_samples_tb <- al_samples_tb %>%
        dplyr::bind_rows(oracle_samples)
}

results_rs <- do.call(rbind, results_lt)
results_rs <- as_tibble(results_rs)
knitr::kable(results_rs, digits = 2)

acc_plot <- results_rs %>%
    tidyr::pivot_longer(-n_samples) %>%
    ggplot2::ggplot() +
    ggplot2::geom_line(ggplot2::aes(x = n_samples,
                                    y = value,
                                    color = name)) +
    ggplot2::ggtitle("Active Learning - Random sampling")
print(acc_plot)

plot(al_label_cube, main = "Random Sampling")

```



## EGAL

```{r egal, echo=FALSE, fig.width=9, fig.height=5}

al_samples_tb <- al_samples_tb %>%
    dplyr::slice(1:n_samples)


results_lt <- list()
for (i in 1:n_iterations) {
    out_dir <- file.path(tempdir(), paste0("iter_egal_", i))
    dir.create(out_dir)

    # NOTE: Since the cube's extent is small, we can run a classification of the
    #       whole area to estimate its accuracy. A more realistic scenario would
    #       use sample points.
    al_sits_model  <- sits::sits_train(al_samples_tb,
                                       ml_method = sits_method)
    al_probs_cube <- sits::sits_classify(data_cube,
                                         ml_model = al_sits_model,
                                         output_dir = out_dir,
                                         memsize = 4,
                                         multicores = n_multicores)
    al_label_cube <- sits::sits_label_classification(al_probs_cube,
                                                     output_dir = out_dir)
    
    # Compute classification's accuracy.
    accuracy_vec <- compute_accuracy(
        ref_rast = ref_rast,
        pred_rast = rast(al_label_cube$file_info[[1]][["path"]]),
        ref_labels = ref_labels
    )
    results_lt[[i]] <- c(n_samples = nrow(al_samples_tb), accuracy_vec)

    if (i == n_iterations)
        next()

    # Get new samples from the pool of samples.
    suppressMessages(
      egal_samples <- al_samples_tb %>%
        sits_al_egal(data_cube,
                     multicores = n_multicores)
    ) 
    
    oracle_samples <- egal_samples %>%
        dplyr::arrange(dplyr::desc(egal)) %>% 
        dplyr::slice(1:n_samples) %>%
        dplyr::select(-egal)
    
    # NOTE: Here we should go to the oracle. Instead, we're getting labels from
    #       the reference raster.
    oracle_sf <-  sf::st_as_sf(oracle_samples,
                               coords = c("longitude", "latitude"),
                               crs = 4326) %>%
        sf::st_transform(crs = crs(ref_rast))
    oracle_labels <- terra::extract(ref_rast, terra::vect(oracle_sf)) %>%
        pull(lyr1) %>%
        recode(!!!ref_labels)

    # Update the labels using data from the oracle.
    oracle_samples[["label"]] <- oracle_labels

    # Merge the new samples to the sample data set.
    al_samples_tb <- al_samples_tb %>%
        dplyr::bind_rows(oracle_samples)

}
results_egal <- do.call(rbind, results_lt)
results_egal <- as_tibble(results_egal)
knitr::kable(results_egal, digits = 2)

acc_plot <- results_egal %>%
    tidyr::pivot_longer(-n_samples) %>%
    ggplot2::ggplot() +
    ggplot2::geom_line(ggplot2::aes(x = n_samples,
                                    y = value,
                                    color = name)) +
    ggplot2::ggtitle("Active Learning - EGAL")
print(acc_plot)

plot(al_label_cube, main = "EGAL")

```

